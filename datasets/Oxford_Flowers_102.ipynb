{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f85fad",
   "metadata": {},
   "source": [
    "# Zero-Shot Classification on Oxford 102 Flower Dataset using CLIP\n",
    "\n",
    "This notebook performs zero-shot classification on the Oxford 102 Flower Dataset using the CLIP model. It includes steps for data loading, preprocessing, model inference, accuracy calculation, error analysis, and visualization of misclassified samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa4474d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import Flowers102\n",
    "from torch.utils.data import DataLoader\n",
    "import clip\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# 设置设备为 GPU（如果可用）\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c866afa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据预处理步骤，CLIP 对图像的输入要求\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # CLIP 通常使用 224x224 的输入\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.48145466, 0.4578275, 0.40821073),\n",
    "                         std=(0.26862954, 0.26130258, 0.27577711))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e28175ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 Oxford-102 Flower Dataset\n",
    "# 使用测试集来评估零样本分类的性能\n",
    "dataset = Flowers102(root=\"../data\", split=\"test\", download=True, transform=preprocess)\n",
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 64\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "169f961d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载 CLIP 模型和预处理器\n",
    "model, preprocess_clip = clip.load(\"ViT-B/32\", device=device)\n",
    "model.eval()  # 设置为评估模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3bed4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取所有类别名称\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# 加载标签文件\n",
    "labels_path = \"../data/flowers-102/imagelabels.mat\"\n",
    "labels_mat = loadmat(labels_path)\n",
    "labels = labels_mat['labels'][0] - 1  # 转换为0索引\n",
    "\n",
    "# 创建类别列表 (0-101)\n",
    "categories = [str(i) for i in range(102)]\n",
    "\n",
    "# 为每个类别创建文本描述\n",
    "# 使用 \"a photo of a {class}\" 的格式\n",
    "text_prompts = [f\"a photo of a {category}\" for category in categories]\n",
    "\n",
    "# 编码文本\n",
    "with torch.no_grad():\n",
    "    text_tokens = clip.tokenize(text_prompts).to(device)  # 将文本转换为 tokens\n",
    "    text_embeddings = model.encode_text(text_tokens)  # 获取文本嵌入\n",
    "    text_embeddings /= text_embeddings.norm(dim=-1, keepdim=True)  # 归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb1ba8c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Flowers102' object has no attribute 'class_to_idx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_421071/2108419746.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 准备标签映射\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 获取类别到索引的映射\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_to_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0midx_to_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Flowers102' object has no attribute 'class_to_idx'"
     ]
    }
   ],
   "source": [
    "# 创建自己的类别映射\n",
    "idx_to_class = {i: str(i) for i in range(102)}  # 如果只用数字标签\n",
    "class_to_idx = {str(i): i for i in range(102)}\n",
    "\n",
    "# 如果你有花名文件，可以这样使用：\n",
    "try:\n",
    "    with open(\"../data/oxford-102-flower-dataset/cat_to_name.json\", 'r') as f:\n",
    "        cat_to_name = json.load(f)\n",
    "        # 注意：cat_to_name 中的键是从1开始的，需要调整为从0开始\n",
    "        idx_to_class = {i: cat_to_name[str(i+1)] for i in range(102)}\n",
    "        class_to_idx = {v: k for k, v in idx_to_class.items()}\n",
    "except:\n",
    "    # 如果没有花名文件，使用数字作为类别名\n",
    "    idx_to_class = {i: str(i) for i in range(102)}\n",
    "    class_to_idx = {str(i): i for i in range(102)}\n",
    "\n",
    "# 确保类别数量一致\n",
    "assert len(categories) == len(text_prompts), \"类别数量不匹配\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee20fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行零样本分类并计算准确率\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 保存预测结果用于后续分析\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "all_images = []\n",
    "\n",
    "# 遍历数据集\n",
    "for images, labels in tqdm(dataloader, desc=\"分类中\"):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_embeddings = model.encode_image(images)\n",
    "        image_embeddings /= image_embeddings.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        # 计算相似度\n",
    "        similarity = image_embeddings @ text_embeddings.T  # [batch_size, num_classes]\n",
    "        preds = similarity.argmax(dim=1)  # 获取最大相似度的类别索引\n",
    "    \n",
    "    # 记录正确预测的数量\n",
    "    correct += (preds == labels).sum().item()\n",
    "    total += labels.size(0)\n",
    "    \n",
    "    # 记录所有预测和标签\n",
    "    all_predictions.extend(preds.cpu().numpy())\n",
    "    all_labels.extend(labels.cpu().numpy())\n",
    "    all_images.extend(images.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0160cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "零样本分类准确率: XX.XX%\n"
     ]
    }
   ],
   "source": [
    "# 计算准确率\n",
    "accuracy = correct / total\n",
    "print(f\"零样本分类准确率: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "597c7d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析每个类别的错误率\n",
    "# 计算每个类别的正确预测数和总样本数\n",
    "class_correct = defaultdict(int)\n",
    "class_total = defaultdict(int)\n",
    "\n",
    "for pred, label in zip(all_predictions, all_labels):\n",
    "    class_total[label] += 1\n",
    "    if pred == label:\n",
    "        class_correct[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9440d1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "错误率最高的10个类别:\n",
      "1. 类别: {类别名称1}, 错误率: YY.YY%\n",
      "2. 类别: {类别名称2}, 错误率: YY.YY%\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# 计算每个类别的错误率\n",
    "class_error_rate = {}\n",
    "for label in class_total:\n",
    "    correct_count = class_correct[label]\n",
    "    total_count = class_total[label]\n",
    "    error = (total_count - correct_count) / total_count\n",
    "    class_error_rate[label] = error\n",
    "\n",
    "# 将类别按错误率排序（从高到低）\n",
    "sorted_error = sorted(class_error_rate.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 打印前10个错误率最高的类别\n",
    "print(\"\\n错误率最高的10个类别:\")\n",
    "for idx, (label, error) in enumerate(sorted_error[:10], 1):\n",
    "    print(f\"{idx}. 类别: {idx_to_class[label]}, 错误率: {error*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66e61040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "选择错误率最高的5个类别进行分析:\n",
      "1. 类别: {类别名称1}, 错误率: YY.YY%\n",
      "2. 类别: {类别名称2}, 错误率: YY.YY%\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# 选择错误率最高的5个类别\n",
    "top_n = 5\n",
    "top_errors = sorted_error[:top_n]\n",
    "top_error_labels = [label for label, _ in top_errors]\n",
    "\n",
    "print(f\"\\n选择错误率最高的{top_n}个类别进行分析:\")\n",
    "for i, label in enumerate(top_error_labels, 1):\n",
    "    print(f\"{i}. 类别: {idx_to_class[label]}, 错误率: {class_error_rate[label]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa278aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个 DataFrame 标记错误分类的样本\n",
    "df = pd.DataFrame({\n",
    "    \"预测类别\": [idx_to_class[pred] for pred in all_predictions],\n",
    "    \"真实类别\": [idx_to_class[label] for label in all_labels],\n",
    "})\n",
    "\n",
    "# 找出错误的预测\n",
    "incorrect_df = df[df[\"预测类别\"] != df[\"真实类别\"]]\n",
    "\n",
    "# 筛选出属于高错误率类别的错误样本\n",
    "high_error_incorrect = df.loc[incorrect_df.index]\n",
    "high_error_incorrect = high_error_incorrect[high_error_incorrect[\"真实类别\"].isin([idx_to_class[label] for label in top_error_labels])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2b95b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置每个类别展示的错误样本数量\n",
    "num_samples_per_class = 5\n",
    "\n",
    "# 随机选择每个类别的错误样本\n",
    "samples_to_display = []\n",
    "for label in top_error_labels:\n",
    "    class_name = idx_to_class[label]\n",
    "    class_errors = high_error_incorrect[high_error_incorrect[\"真实类别\"] == class_name]\n",
    "    if not class_errors.empty:\n",
    "        sampled = class_errors.sample(n=min(num_samples_per_class, len(class_errors)), random_state=42)\n",
    "        samples_to_display.extend(sampled.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6f417f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展示错误分类的图像\n",
    "plt.figure(figsize=(20, 4 * top_n))\n",
    "for i, idx in enumerate(samples_to_display, 1):\n",
    "    row = df.iloc[idx]\n",
    "    img = all_images[idx]\n",
    "    img = img.permute(1, 2, 0).numpy()\n",
    "    img = (img * np.array([0.26862954, 0.26130258, 0.27577711]) + \n",
    "           np.array([0.48145466, 0.4578275, 0.40821073]))\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    plt.subplot(top_n, num_samples_per_class, i)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Predicted: {row['预测类别']}\\nTrue: {row['真实类别']}\")\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"错误率最高类别的错误分类案例\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42608837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建混淆矩阵\n",
    "# 选择高错误率类别的标签和预测\n",
    "filtered_labels = []\n",
    "filtered_preds = []\n",
    "for pred, label in zip(all_predictions, all_labels):\n",
    "    if label in top_error_labels:\n",
    "        filtered_labels.append(label)\n",
    "        filtered_preds.append(pred)\n",
    "\n",
    "# 生成混淆矩阵\n",
    "cm = confusion_matrix(filtered_labels, filtered_preds, labels=top_error_labels)\n",
    "\n",
    "# 绘制热力图\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', \n",
    "            xticklabels=[idx_to_class[label] for label in top_error_labels],\n",
    "            yticklabels=[idx_to_class[label] for label in top_error_labels],\n",
    "            cmap='Blues')\n",
    "plt.xlabel('预测类别')\n",
    "plt.ylabel('真实类别')\n",
    "plt.title('高错误率类别的混淆矩阵')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "868e4e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "总样本数: XXXX\n",
      "正确预测数: XXXX\n",
      "错误预测数: XXXX\n",
      "零样本分类准确率: XX.XX%\n",
      "错误率最高的类别及其错误率已展示。\n"
     ]
    }
   ],
   "source": [
    "# 总结\n",
    "print(f\"\\n总样本数: {total}\")\n",
    "print(f\"正确预测数: {correct}\")\n",
    "print(f\"错误预测数: {total - correct}\")\n",
    "print(f\"零样本分类准确率: {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
