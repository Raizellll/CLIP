{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CLIPText Implementation with AG News Dataset\n",
                "\n",
                "This notebook implements the CLIPText approach for zero-shot text classification using the AG News dataset. AG News contains news articles in 4 categories:\n",
                "1. World\n",
                "2. Sports\n",
                "3. Business\n",
                "4. Tech/Sci"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
                        "[nltk_data]   Package punkt is already up-to-date!\n",
                        "Found cached dataset parquet (/root/.cache/huggingface/datasets/parquet/ag_news-92271709ed454db0/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "eeef5912da264e2d825e1c68176a903f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/2 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Cell 1: 导入必要的包\n",
                "import torch\n",
                "import clip\n",
                "from datasets import load_dataset\n",
                "import numpy as np\n",
                "from tqdm import tqdm\n",
                "from sklearn.metrics import classification_report\n",
                "import os\n",
                "import torch.nn.functional as F\n",
                "from PIL import Image, ImageDraw\n",
                "import re\n",
                "from nltk.stem import PorterStemmer\n",
                "from nltk.tokenize import word_tokenize\n",
                "import nltk\n",
                "nltk.download('punkt')\n",
                "\n",
                "# 加载模型和数据集\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
                "dataset = load_dataset(\"ag_news\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Creating category images...\n",
                        "Processing category: World News\n",
                        "Saved image variant 0 to agnews_images/category_0_variant_0.jpg\n",
                        "Saved image variant 1 to agnews_images/category_0_variant_1.jpg\n",
                        "Saved image variant 2 to agnews_images/category_0_variant_2.jpg\n",
                        "Successfully processed all variants for World News\n",
                        "\n",
                        "Processing category: Sports News\n",
                        "Saved image variant 0 to agnews_images/category_1_variant_0.jpg\n",
                        "Saved image variant 1 to agnews_images/category_1_variant_1.jpg\n",
                        "Saved image variant 2 to agnews_images/category_1_variant_2.jpg\n",
                        "Successfully processed all variants for Sports News\n",
                        "\n",
                        "Processing category: Business News\n",
                        "Saved image variant 0 to agnews_images/category_2_variant_0.jpg\n",
                        "Saved image variant 1 to agnews_images/category_2_variant_1.jpg\n",
                        "Saved image variant 2 to agnews_images/category_2_variant_2.jpg\n",
                        "Successfully processed all variants for Business News\n",
                        "\n",
                        "Processing category: Technology and Science News\n",
                        "Saved image variant 0 to agnews_images/category_3_variant_0.jpg\n",
                        "Saved image variant 1 to agnews_images/category_3_variant_1.jpg\n",
                        "Saved image variant 2 to agnews_images/category_3_variant_2.jpg\n",
                        "Successfully processed all variants for Technology and Science News\n",
                        "\n",
                        "Preprocessing category images...\n",
                        "Processed features for World News\n",
                        "Processed features for Sports News\n",
                        "Processed features for Business News\n",
                        "Processed features for Technology and Science News\n"
                    ]
                }
            ],
            "source": [
                "# Cell 2: 创建类别图像和特征\n",
                "categories = {\n",
                "    0: \"World News\",\n",
                "    1: \"Sports News\", \n",
                "    2: \"Business News\",\n",
                "    3: \"Technology and Science News\"\n",
                "}\n",
                "\n",
                "# 为每个类别定义关键词和特征\n",
                "category_keywords = {\n",
                "    0: [\"global\", \"international\", \"world\", \"country\", \"nation\", \"political\", \"government\"],\n",
                "    1: [\"sports\", \"game\", \"player\", \"team\", \"tournament\", \"championship\", \"athlete\"],\n",
                "    2: [\"business\", \"market\", \"economy\", \"company\", \"financial\", \"trade\", \"stock\"],\n",
                "    3: [\"technology\", \"science\", \"research\", \"innovation\", \"digital\", \"tech\", \"scientific\"]\n",
                "}\n",
                "\n",
                "def create_category_image(label, size=(224, 224), variation=0):\n",
                "    \"\"\"创建更具区分性的类别图像\"\"\"\n",
                "    img = Image.new('RGB', size, 'white')\n",
                "    draw = ImageDraw.Draw(img)\n",
                "    \n",
                "    # 基础渐变\n",
                "    arr = np.zeros((size[0], size[1], 3), dtype=np.uint8)\n",
                "    \n",
                "    if label == 0:  # World News\n",
                "        arr[:, :, 2] = np.linspace(100, 255, size[0])[:, None]\n",
                "        if variation == 0:\n",
                "            draw.ellipse([40, 40, 184, 184], outline='white', width=4)\n",
                "            draw.line([40, 112, 184, 112], fill='white', width=3)\n",
                "        elif variation == 1:\n",
                "            for i in range(4):\n",
                "                x = 60 + i * 40\n",
                "                draw.ellipse([x, 90, x+30, 120], outline='white', width=2)\n",
                "        else:\n",
                "            for i in range(4):\n",
                "                draw.line([0, i*60, 224, 224-i*60], fill='white', width=2)\n",
                "                \n",
                "    elif label == 1:  # Sports News\n",
                "        arr[:, :, 1] = np.linspace(100, 255, size[0])[:, None]\n",
                "        if variation == 0:\n",
                "            draw.ellipse([70, 70, 154, 154], outline='white', width=4)\n",
                "            draw.line([70, 112, 154, 112], fill='white', width=2)\n",
                "        elif variation == 1:\n",
                "            draw.rectangle([50, 50, 174, 174], outline='white', width=3)\n",
                "            draw.line([112, 50, 112, 174], fill='white', width=2)\n",
                "        else:\n",
                "            # 使用线条绘制人形图标\n",
                "            points = [(112, 50), (90, 100), (134, 100)]\n",
                "            # 绘制三角形的三条边\n",
                "            draw.line([points[0], points[1]], fill='white', width=2)\n",
                "            draw.line([points[1], points[2]], fill='white', width=2)\n",
                "            draw.line([points[2], points[0]], fill='white', width=2)\n",
                "            # 绘制身体\n",
                "            draw.line([112, 100, 112, 150], fill='white', width=2)\n",
                "            \n",
                "    elif label == 2:  # Business News\n",
                "        arr[:, :, 0] = np.linspace(100, 255, size[0])[:, None]\n",
                "        if variation == 0:\n",
                "            points = [(50,174), (90,130), (130,90), (174,50)]\n",
                "            draw.line(points, fill='white', width=3)\n",
                "        elif variation == 1:\n",
                "            draw.text((90, 90), \"$\", fill='white', size=60)\n",
                "        else:\n",
                "            for i in range(4):\n",
                "                height = 40 + i * 30\n",
                "                draw.rectangle([50+i*40, 224-height, 80+i*40, 224], outline='white', width=2)\n",
                "            \n",
                "    else:  # Tech News\n",
                "        arr[:, :, 0] = np.linspace(100, 200, size[0])[:, None]\n",
                "        arr[:, :, 2] = np.linspace(100, 200, size[0])[:, None]\n",
                "        if variation == 0:\n",
                "            for i in range(5):\n",
                "                draw.line([0, i*50, 224, i*50], fill='white', width=2)\n",
                "                draw.line([i*50, 0, i*50, 224], fill='white', width=2)\n",
                "        elif variation == 1:\n",
                "            for i in range(5):\n",
                "                for j in range(5):\n",
                "                    draw.text((30+i*40, 30+j*40), \"01\", fill='white')\n",
                "        else:\n",
                "            draw.rectangle([60, 60, 164, 164], outline='white', width=3)\n",
                "            draw.line([60, 112, 164, 112], fill='white', width=2)\n",
                "            draw.line([112, 60, 112, 164], fill='white', width=2)\n",
                "    \n",
                "    img = Image.fromarray(arr)\n",
                "    return img\n",
                "\n",
                "# 创建和处理类别图像\n",
                "print(\"Creating category images...\")\n",
                "category_images = {}\n",
                "for label in categories.keys():\n",
                "    print(f\"Processing category: {categories[label]}\")\n",
                "    \n",
                "    # 创建多个变体\n",
                "    processed_variants = []\n",
                "    for i in range(3):  # 每个类别创建3个变体\n",
                "        img = create_category_image(label, variation=i)\n",
                "        img_path = f'agnews_images/category_{label}_variant_{i}.jpg'\n",
                "        img.save(img_path)\n",
                "        print(f\"Saved image variant {i} to {img_path}\")\n",
                "        \n",
                "        processed_img = preprocess(img).unsqueeze(0).to(device)\n",
                "        processed_variants.append(processed_img)\n",
                "    \n",
                "    category_images[label] = processed_variants\n",
                "    print(f\"Successfully processed all variants for {categories[label]}\\n\")\n",
                "\n",
                "# 预处理并缓存图像特征\n",
                "print(\"Preprocessing category images...\")\n",
                "category_features = {}\n",
                "for label, img_variants in category_images.items():\n",
                "    features = []\n",
                "    with torch.no_grad():\n",
                "        for img in img_variants:\n",
                "            features.append(model.encode_image(img))\n",
                "    category_features[label] = features\n",
                "    print(f\"Processed features for {categories[label]}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 3: 定义预测函数\n",
                "def clean_text(text):\n",
                "    \"\"\"增强的文本清理函数\"\"\"\n",
                "    text = re.sub(r'<[^>]+>', '', text)\n",
                "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
                "    text = re.sub(r'[^\\w\\s.,!?-]', ' ', text)\n",
                "    text = ' '.join(text.split())\n",
                "    \n",
                "    ps = PorterStemmer()\n",
                "    words = word_tokenize(text)\n",
                "    text = ' '.join([ps.stem(word) for word in words])\n",
                "    \n",
                "    return text\n",
                "\n",
                "def predict_basic_clip(text):\n",
                "    \"\"\"基础CLIP方法 - 不使用prompt\"\"\"\n",
                "    text_input = clip.tokenize([text[:250]]).to(device)\n",
                "    with torch.no_grad():\n",
                "        text_features = model.encode_text(text_input)\n",
                "        \n",
                "        similarities = {}\n",
                "        for label, img_features_list in category_features.items():\n",
                "            img_similarities = []\n",
                "            for img_features in img_features_list:\n",
                "                similarity = F.cosine_similarity(text_features, img_features)\n",
                "                img_similarities.append(similarity.item())\n",
                "            similarities[label] = np.mean(img_similarities)\n",
                "            \n",
                "        return max(similarities.items(), key=lambda x: x[1])[0]\n",
                "\n",
                "def predict_simple_prompt(text):\n",
                "    \"\"\"简单Prompt方法 - 使用单一prompt模板\"\"\"\n",
                "    prompted_text = f\"This is a news article about: {text[:250]}\"\n",
                "    text_input = clip.tokenize([prompted_text]).to(device)\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        text_features = model.encode_text(text_input)\n",
                "        \n",
                "        similarities = {}\n",
                "        for label, img_features_list in category_features.items():\n",
                "            img_similarities = []\n",
                "            for img_features in img_features_list:\n",
                "                similarity = F.cosine_similarity(text_features, img_features)\n",
                "                img_similarities.append(similarity.item())\n",
                "            similarities[label] = np.mean(img_similarities)\n",
                "            \n",
                "        return max(similarities.items(), key=lambda x: x[1])[0]\n",
                "\n",
                "def predict_category_with_confidence(text):\n",
                "    \"\"\"完整的PROMPT-CLIPTEXT方法\"\"\"\n",
                "    cleaned_text = clean_text(text)\n",
                "    \n",
                "    # 计算文本中包含的类别关键词\n",
                "    keyword_scores = {label: 0 for label in categories.keys()}\n",
                "    for label, keywords in category_keywords.items():\n",
                "        for keyword in keywords:\n",
                "            if keyword in cleaned_text.lower():\n",
                "                keyword_scores[label] += 1\n",
                "    \n",
                "    max_score = max(keyword_scores.values()) + 1e-6\n",
                "    keyword_weights = {k: v/max_score for k, v in keyword_scores.items()}\n",
                "    \n",
                "    # 创建多个prompt\n",
                "    prompts = [\n",
                "        f\"This is a news article discussing: {cleaned_text[:250]}\",\n",
                "        f\"Here's a news report about: {cleaned_text[:250]}\",\n",
                "        f\"Breaking news story: {cleaned_text[:250]}\"\n",
                "    ]\n",
                "    \n",
                "    # 添加类别特定的prompt\n",
                "    category_prompts = {\n",
                "        0: [f\"International news coverage: {cleaned_text[:250]}\"],\n",
                "        1: [f\"Sports coverage about: {cleaned_text[:250]}\"],\n",
                "        2: [f\"Business and finance report: {cleaned_text[:250]}\"],\n",
                "        3: [f\"Tech and science report about: {cleaned_text[:250]}\"]\n",
                "    }\n",
                "    \n",
                "    for category_specific_prompts in category_prompts.values():\n",
                "        prompts.extend(category_specific_prompts)\n",
                "    \n",
                "    similarities = {label: [] for label in categories.keys()}\n",
                "    \n",
                "    for prompted_text in prompts:\n",
                "        text_input = clip.tokenize([prompted_text]).to(device)\n",
                "        with torch.no_grad():\n",
                "            text_features = model.encode_text(text_input)\n",
                "            \n",
                "            for label, img_features_list in category_features.items():\n",
                "                prompt_similarities = []\n",
                "                for img_features in img_features_list:\n",
                "                    similarity = F.cosine_similarity(text_features, img_features)\n",
                "                    prompt_similarities.append(similarity.item())\n",
                "                \n",
                "                top_similarities = sorted(prompt_similarities, reverse=True)[:2]\n",
                "                similarities[label].append(np.mean(top_similarities))\n",
                "    \n",
                "    final_scores = {}\n",
                "    for label in categories.keys():\n",
                "        clip_score = np.mean(similarities[label])\n",
                "        keyword_weight = keyword_weights[label]\n",
                "        \n",
                "        class_weight = 1.0\n",
                "        if label == 1:  # Sports News\n",
                "            class_weight = 1.2\n",
                "        elif label == 2:  # Business News\n",
                "            class_weight = 0.8\n",
                "            \n",
                "        final_scores[label] = clip_score * (0.7 + 0.3 * keyword_weight) * class_weight\n",
                "    \n",
                "    max_score = max(final_scores.values())\n",
                "    max_label = max(final_scores.items(), key=lambda x: x[1])[0]\n",
                "    \n",
                "    confidence = max_score / (sum(final_scores.values()) + 1e-6)\n",
                "    \n",
                "    if confidence < 0.3:\n",
                "        sorted_scores = sorted(final_scores.items(), key=lambda x: x[1], reverse=True)\n",
                "        if len(sorted_scores) > 1:\n",
                "            max_label = sorted_scores[1][0]\n",
                "    \n",
                "    return max_label, confidence, final_scores\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Evaluating Basic CLIP...\n",
                        "Progress: 20/100, Current accuracy: 15.00%\n",
                        "Progress: 40/100, Current accuracy: 10.00%\n",
                        "Progress: 60/100, Current accuracy: 15.00%\n",
                        "Progress: 80/100, Current accuracy: 15.00%\n",
                        "Error processing text: Staples Profit Up, to Enter China Market  NEW YORK...\n",
                        "Error: Input Staples Profit Up, to Enter China Market  NEW YORK (Reuters) - Staples Inc. &lt;A HREF=\"http://www.investor.reuters.com/FullQuote.aspx?ticker=SPLS.O target=/stocks/quickinfo/fullquote\"&gt;SPLS.O&lt;/A&gt;, the top U.S.  office products retailer, on T is too long for context length 77\n",
                        "Progress: 100/100, Current accuracy: 18.18%\n",
                        "\n",
                        "=== Basic CLIP Classification Report ===\n",
                        "                             precision    recall  f1-score   support\n",
                        "\n",
                        "                 World News       0.18      0.07      0.10        30\n",
                        "                Sports News       0.00      0.00      0.00        21\n",
                        "              Business News       0.13      0.83      0.22        12\n",
                        "Technology and Science News       0.86      0.16      0.27        37\n",
                        "\n",
                        "                   accuracy                           0.18       100\n",
                        "                  macro avg       0.29      0.27      0.15       100\n",
                        "               weighted avg       0.39      0.18      0.16       100\n",
                        "\n",
                        "\n",
                        "Evaluating Simple Prompt...\n",
                        "Progress: 20/100, Current accuracy: 10.00%\n",
                        "Progress: 40/100, Current accuracy: 5.00%\n",
                        "Progress: 60/100, Current accuracy: 10.00%\n",
                        "Progress: 80/100, Current accuracy: 10.00%\n",
                        "Error processing text: Staples Profit Up, to Enter China Market  NEW YORK...\n",
                        "Error: Input This is a news article about: Staples Profit Up, to Enter China Market  NEW YORK (Reuters) - Staples Inc. &lt;A HREF=\"http://www.investor.reuters.com/FullQuote.aspx?ticker=SPLS.O target=/stocks/quickinfo/fullquote\"&gt;SPLS.O&lt;/A&gt;, the top U.S.  office products retailer, on T is too long for context length 77\n",
                        "Progress: 100/100, Current accuracy: 13.13%\n",
                        "\n",
                        "=== Simple Prompt Classification Report ===\n",
                        "                             precision    recall  f1-score   support\n",
                        "\n",
                        "                 World News       0.11      0.03      0.05        30\n",
                        "                Sports News       0.00      0.00      0.00        21\n",
                        "              Business News       0.12      0.83      0.21        12\n",
                        "Technology and Science News       0.67      0.05      0.10        37\n",
                        "\n",
                        "                   accuracy                           0.13       100\n",
                        "                  macro avg       0.22      0.23      0.09       100\n",
                        "               weighted avg       0.29      0.13      0.08       100\n",
                        "\n",
                        "\n",
                        "Evaluating PROMPT-CLIPTEXT...\n",
                        "Error processing text: Loosing the War on Terrorism \\\\\"Sven Jaschan, self...\n",
                        "Error: Input This is a news article discussing: loos the war on terror sven jaschan , self-confess author of the netski and sasser virus , is respons for 70 percent of viru infect in 2004 , accord to a six-month viru roundup publish wednesday by antiviru compani sopho . the 18-year-old jaschan wa  is too long for context length 77\n",
                        "Progress: 20/100, Current accuracy: 15.79%\n",
                        "Error processing text: Tougher rules won't soften Law's game FOXBOROUGH -...\n",
                        "Error: Input This is a news article discussing: tougher rule won t soften law s game foxborough -- look at hi ridicul develop upper bodi , with huge bicep and hardli an ounc of fat , it s easi to see whi ty law , arguabl the best cornerback in footbal , choos physic play over finess . that s not t is too long for context length 77\n",
                        "Error processing text: Man Sought  #36;50M From McGreevey, Aides Say (AP)...\n",
                        "Error: Input This is a news article discussing: man sought 36 50m from mcgreevey , aid say ap ap - the man who claim gov . jame e. mcgreevey sexual harass him wa push for a cash settlement of up to 36 50 million befor the governor decid to announc that he wa gay and had an extramarit affair , sour is too long for context length 77\n",
                        "Progress: 40/100, Current accuracy: 21.62%\n",
                        "Progress: 60/100, Current accuracy: 31.58%\n",
                        "Error processing text: Natalie Coughlin Wins 100M Backstroke (AP) AP - Am...\n",
                        "Error: Input This is a news article discussing: natali coughlin win 100m backstrok ap ap - american natali coughlin won olymp gold in the 100-meter backstrok monday night . coughlin , the onli woman ever to swim under 1 minut in the event , finish first in 1 minut , 0.37 second . kirsti coventri o is too long for context length 77\n",
                        "Progress: 80/100, Current accuracy: 43.42%\n",
                        "Error processing text: Staples Profit Up, to Enter China Market  NEW YORK...\n",
                        "Error: Input This is a news article discussing: stapl profit up , to enter china market new york reuter - stapl inc. lt a href target stock quickinfo fullquot gt spls.o lt a gt , the top u.s. offic product retail , on tuesday report a 39 percent jump in quarterli profit , rais it full-year forecas is too long for context length 77\n",
                        "Progress: 100/100, Current accuracy: 44.21%\n",
                        "\n",
                        "=== PROMPT-CLIPTEXT Classification Report ===\n",
                        "                             precision    recall  f1-score   support\n",
                        "\n",
                        "                 World News       0.48      0.73      0.58        30\n",
                        "                Sports News       0.24      0.43      0.31        21\n",
                        "              Business News       0.50      0.25      0.33        12\n",
                        "Technology and Science News       0.82      0.24      0.38        37\n",
                        "\n",
                        "                   accuracy                           0.43       100\n",
                        "                  macro avg       0.51      0.41      0.40       100\n",
                        "               weighted avg       0.56      0.43      0.42       100\n",
                        "\n",
                        "\n",
                        "=== Methods Comparison ===\n",
                        "Method               Accuracy   Macro F1  \n",
                        "----------------------------------------\n",
                        "Basic CLIP           0.180     0.148\n",
                        "Simple Prompt        0.130     0.089\n",
                        "PROMPT-CLIPTEXT      0.430     0.399\n"
                    ]
                }
            ],
            "source": [
                "# Cell 4: 对比实验\n",
                "def evaluate_method(predict_fn, test_texts, test_labels, method_name):\n",
                "    predictions = []\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    \n",
                "    print(f\"\\nEvaluating {method_name}...\")\n",
                "    for i, (text, true_label) in enumerate(zip(test_texts, test_labels)):\n",
                "        try:\n",
                "            if predict_fn == predict_category_with_confidence:\n",
                "                pred, _, _ = predict_fn(text)\n",
                "            else:\n",
                "                pred = predict_fn(text)\n",
                "                \n",
                "            predictions.append(pred)\n",
                "            is_correct = pred == true_label\n",
                "            if is_correct:\n",
                "                correct += 1\n",
                "            total += 1\n",
                "            \n",
                "            if (i + 1) % 20 == 0:\n",
                "                print(f\"Progress: {i+1}/{len(test_texts)}, Current accuracy: {correct/total:.2%}\")\n",
                "                \n",
                "        except Exception as e:\n",
                "            print(f\"Error processing text: {text[:50]}...\")\n",
                "            print(f\"Error: {str(e)}\")\n",
                "            predictions.append(0)\n",
                "    \n",
                "    print(f\"\\n=== {method_name} Classification Report ===\")\n",
                "    report = classification_report(test_labels, predictions, \n",
                "                                 target_names=[categories[i] for i in range(4)],\n",
                "                                 output_dict=True)\n",
                "    print(classification_report(test_labels, predictions, \n",
                "                              target_names=[categories[i] for i in range(4)]))\n",
                "    return report\n",
                "\n",
                "# 运行对比实验\n",
                "test_size = 100\n",
                "test_texts = dataset['test']['text'][:test_size]\n",
                "test_labels = dataset['test']['label'][:test_size]\n",
                "\n",
                "# 评估三种方法\n",
                "basic_results = evaluate_method(predict_basic_clip, test_texts, test_labels, \"Basic CLIP\")\n",
                "simple_prompt_results = evaluate_method(predict_simple_prompt, test_texts, test_labels, \"Simple Prompt\")\n",
                "full_prompt_results = evaluate_method(predict_category_with_confidence, test_texts, test_labels, \"PROMPT-CLIPTEXT\")\n",
                "\n",
                "# 打印对比结果\n",
                "print(\"\\n=== Methods Comparison ===\")\n",
                "print(f\"{'Method':<20} {'Accuracy':<10} {'Macro F1':<10}\")\n",
                "print(\"-\" * 40)\n",
                "print(f\"{'Basic CLIP':<20} {basic_results['accuracy']:.3f}     {basic_results['macro avg']['f1-score']:.3f}\")\n",
                "print(f\"{'Simple Prompt':<20} {simple_prompt_results['accuracy']:.3f}     {simple_prompt_results['macro avg']['f1-score']:.3f}\")\n",
                "print(f\"{'PROMPT-CLIPTEXT':<20} {full_prompt_results['accuracy']:.3f}     {full_prompt_results['macro avg']['f1-score']:.3f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Running benchmark comparisons...\n"
                    ]
                },
                {
                    "ename": "NameError",
                    "evalue": "name 'train_evaluate_bert' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipykernel_504730/817527033.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# BERT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mbert_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_evaluate_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BERT (Few-shot)'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'report'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbert_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'time'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbert_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predictions'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbert_preds\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'train_evaluate_bert' is not defined"
                    ]
                }
            ],
            "source": [
                "# Cell 5: 基准模型比较\n",
                "def train_evaluate_xgboost():\n",
                "    print(\"\\nTraining and evaluating XGBoost + TF-IDF (Few-shot Learning)...\")\n",
                "    start_time = time.time()\n",
                "    \n",
                "    # TF-IDF特征提取\n",
                "    print(\"Extracting TF-IDF features...\")\n",
                "    vectorizer = TfidfVectorizer(max_features=5000)\n",
                "    X_train = vectorizer.fit_transform(train_texts)\n",
                "    X_test = vectorizer.transform(test_texts)\n",
                "    \n",
                "    # 训练XGBoost\n",
                "    print(\"Training XGBoost model...\")\n",
                "    model = xgb.XGBClassifier(\n",
                "        max_depth=7,\n",
                "        learning_rate=0.1,\n",
                "        n_estimators=100,\n",
                "        use_label_encoder=False,\n",
                "        eval_metric='mlogloss',\n",
                "        verbose=1\n",
                "    )\n",
                "    \n",
                "    # 训练模型\n",
                "    eval_set = [(X_test, test_labels)]\n",
                "    model.fit(X_train, train_labels, eval_set=eval_set, verbose=True)\n",
                "    \n",
                "    # 预测\n",
                "    print(\"Making predictions...\")\n",
                "    predictions = model.predict(X_test)\n",
                "    \n",
                "    training_time = time.time() - start_time\n",
                "    \n",
                "    # 计算指标\n",
                "    report = classification_report(test_labels, predictions, \n",
                "                                 target_names=[categories[i] for i in range(4)],\n",
                "                                 output_dict=True)\n",
                "    \n",
                "    return report, training_time, predictions\n",
                "\n",
                "# 运行基准模型\n",
                "print(\"\\nRunning benchmark comparisons...\")\n",
                "results = {}\n",
                "\n",
                "# BERT\n",
                "bert_report, bert_time, bert_preds = train_evaluate_bert()\n",
                "results['BERT (Few-shot)'] = {'report': bert_report, 'time': bert_time, 'predictions': bert_preds}\n",
                "\n",
                "# XGBoost\n",
                "xgboost_report, xgboost_time, xgboost_preds = train_evaluate_xgboost()\n",
                "results['XGBoost (Few-shot)'] = {'report': xgboost_report, 'time': xgboost_time, 'predictions': xgboost_preds}\n",
                "\n",
                "# 为PROMPT-CLIPTEXT生成预测结果\n",
                "prompt_predictions = []\n",
                "for text in test_texts[:100]:  # 使用与之前相同的100个测试样本\n",
                "    try:\n",
                "        pred, _, _ = predict_category_with_confidence(text)\n",
                "        prompt_predictions.append(pred)\n",
                "    except Exception as e:\n",
                "        prompt_predictions.append(0)\n",
                "        print(f\"Error in PROMPT-CLIPTEXT prediction: {str(e)}\")\n",
                "\n",
                "# 添加CLIP结果\n",
                "results['PROMPT-CLIPTEXT (Zero-shot)'] = {\n",
                "    'report': full_prompt_results,\n",
                "    'time': None,\n",
                "    'predictions': prompt_predictions\n",
                "}\n",
                "\n",
                "# 打印比较结果\n",
                "print(\"\\n=== Model Comparison ===\")\n",
                "print(f\"{'Model':<25} {'Accuracy':<10} {'Macro F1':<10} {'Training Time':<15}\")\n",
                "print(\"-\" * 60)\n",
                "\n",
                "for model_name, result in results.items():\n",
                "    accuracy = result['report']['accuracy']\n",
                "    macro_f1 = result['report']['macro avg']['f1-score']\n",
                "    time_str = f\"{result['time']:.2f}s\" if result['time'] else \"N/A\"\n",
                "    print(f\"{model_name:<25} {accuracy:.3f}     {macro_f1:.3f}     {time_str}\")\n",
                "\n",
                "# 打印详细分类报告\n",
                "for model_name, result in results.items():\n",
                "    print(f\"\\n=== {model_name} Detailed Report ===\")\n",
                "    if model_name == 'PROMPT-CLIPTEXT (Zero-shot)':\n",
                "        # 只使用前100个样本进行评估\n",
                "        print(classification_report(test_labels[:100], result['predictions'],\n",
                "                                 target_names=[categories[i] for i in range(4)]))\n",
                "    else:\n",
                "        # 使用全部测试集\n",
                "        print(classification_report(test_labels, result['predictions'],\n",
                "                                 target_names=[categories[i] for i in range(4)]))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python (clip)",
            "language": "python",
            "name": "clip"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
