{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL导入成功\n",
      "CLIP导入成功\n"
     ]
    }
   ],
   "source": [
    "# 先测试PIL是否正常\n",
    "from PIL import Image\n",
    "print(\"PIL导入成功\")\n",
    "\n",
    "# 然后测试CLIP\n",
    "import clip\n",
    "print(\"CLIP导入成功\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL导入成功\n",
      "CLIP导入成功\n",
      "PIL版本: 7.1.2\n"
     ]
    }
   ],
   "source": [
    "# 测试基础包的导入\n",
    "try:\n",
    "    from PIL import Image\n",
    "    print(\"PIL导入成功\")\n",
    "except ImportError as e:\n",
    "    print(\"PIL导入失败:\", e)\n",
    "\n",
    "try:\n",
    "    import clip\n",
    "    print(\"CLIP导入成功\")\n",
    "except ImportError as e:\n",
    "    print(\"CLIP导入失败:\", e)\n",
    "\n",
    "# 打印版本信息以便调试\n",
    "import PIL\n",
    "print(\"PIL版本:\", PIL.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP location: /root/ENTER/envs/clip/lib/python3.7/site-packages/clip/__init__.py\n",
      "Using device: cuda\n",
      "Loading CLIP model...\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "# 打印 CLIP 版本和位置以确认我们使用的是正确的包\n",
    "import inspect\n",
    "print(\"CLIP location:\", inspect.getfile(clip))\n",
    "\n",
    "# 检查设备\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 加载模型\n",
    "print(\"Loading CLIP model...\")\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label probs: [[0.00902 0.0856  0.9053 ]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "image = preprocess(Image.open(\"wideCat.png\")).unsqueeze(0).to(device)\n",
    "text = clip.tokenize([\"a diagram\", \"a dog\", \"a cat\"]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    \n",
    "    logits_per_image, logits_per_text = model(image, text)\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "print(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421068 0.00299572]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top predictions:\n",
      "\n",
      "            fish: 16.54%\n",
      "             cat: 15.78%\n",
      "            lion: 14.83%\n",
      "             dog: 10.35%\n",
      "          monkey: 9.58%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)\n",
    "\n",
    "# Load and preprocess the image\n",
    "image = Image.open(\"BlueCandyCatGirl.png\") # 使用本地图片\n",
    "image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "\n",
    "# Prepare the text inputs\n",
    "classes = [\"cat\", \"dog\", \"bird\", \"fish\", \"horse\", \"elephant\", \"monkey\", \"tiger\", \"lion\", \"bear\"]\n",
    "text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in classes]).to(device)\n",
    "\n",
    "# Calculate features\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image_input)\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "\n",
    "# Pick the top 5 most similar labels for the image\n",
    "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "values, indices = similarity[0].topk(5)\n",
    "\n",
    "# Print the result\n",
    "print(\"\\nTop predictions:\\n\")\n",
    "for value, index in zip(values, indices):\n",
    "    print(f\"{classes[index]:>16s}: {100 * value.item():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "\n",
      "Top predictions:\n",
      "\n",
      "          lizard: 8.34%\n",
      "         hamster: 7.95%\n",
      "          possum: 7.02%\n",
      "          turtle: 4.98%\n",
      "           mouse: 4.46%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "from torchvision.datasets import CIFAR100\n",
    "from PIL import Image\n",
    "\n",
    "# Load CIFAR100 dataset for its classes\n",
    "cifar100 = CIFAR100(root='./data', download=True, train=False)\n",
    "\n",
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load('ViT-B/32', device)\n",
    "\n",
    "# Load and preprocess the image\n",
    "image = Image.open(\"wideCat.png\") # 使用本地图片\n",
    "image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "\n",
    "# Prepare the text inputs\n",
    "text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in cifar100.classes]).to(device)\n",
    "\n",
    "# Calculate features\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image_input)\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "\n",
    "# Pick the top 5 most similar labels for the image\n",
    "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "values, indices = similarity[0].topk(5)\n",
    "\n",
    "# Print the result\n",
    "print(\"\\nTop predictions:\\n\")\n",
    "for value, index in zip(values, indices):\n",
    "    print(f\"{cifar100.classes[index]:>16s}: {100 * value.item():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top predictions:\n",
      "\n",
      "classes:not_cup score:0.93\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "from torchvision.datasets import CIFAR100\n",
    "from PIL import Image\n",
    "\n",
    "img_path = 'CLIP.png'\n",
    "classes = ['cup', 'not_cup']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#准备输入集\n",
    "image = Image.open(img_path)\n",
    "image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in classes]).to(device) #生成文字描述\n",
    "\n",
    "#特征编码\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image_input)\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "\n",
    "#选取参数最高的标签\n",
    "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1) #对图像描述和图像特征  \n",
    "values, indices = similarity[0].topk(1)\n",
    "\n",
    "#输出结果\n",
    "print(\"\\nTop predictions:\\n\")\n",
    "print('classes:{} score:{:.2f}'.format(classes[indices.item()], values.item()))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (clip)",
   "language": "python",
   "name": "clip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
