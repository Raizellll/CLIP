{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[1]: 导入所需的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.cuda.amp import GradScaler\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10, CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[2]: 定义图像编码器\n",
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self, mode='finetune'):\n",
    "        super().__init__()\n",
    "        weights = ResNet50_Weights.IMAGENET1K_V1\n",
    "        self.resnet = resnet50(weights=weights)\n",
    "        \n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-2])\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = torch.reshape(x, (x.shape[0], x.shape[1]))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[3]: 定义文本编码器\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained('openai-community/gpt2')\n",
    "        self.model = GPT2Model.from_pretrained('openai-community/gpt2')\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "    def forward(self, texts):\n",
    "        inputs = self.tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[4]: 定义CLIP模型\n",
    "class CLIP(nn.Module):\n",
    "    def __init__(self, embedding_dim=512):\n",
    "        super().__init__()\n",
    "        self.image_encoder = ImageEncoder()\n",
    "        self.text_encoder = TextEncoder()\n",
    "        \n",
    "        # 投影层\n",
    "        self.image_projection = nn.Linear(2048, embedding_dim)\n",
    "        self.text_projection = nn.Linear(768, embedding_dim)\n",
    "        \n",
    "        # 额外的线性层\n",
    "        self.image_layer1 = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.text_layer1 = nn.Linear(embedding_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, image, text):\n",
    "        image_embedding = self.image_encoder(image)\n",
    "        text_embedding = self.text_encoder(text)\n",
    "        \n",
    "        image_embedding = self.image_projection(image_embedding)\n",
    "        text_embedding = self.text_projection(text_embedding)\n",
    "        \n",
    "        image_embedding = self.image_layer1(image_embedding)\n",
    "        text_embedding = self.text_layer1(text_embedding)\n",
    "        \n",
    "        # 标准化embeddings\n",
    "        image_embedding = F.normalize(image_embedding, p=2, dim=-1)\n",
    "        text_embedding = F.normalize(text_embedding, p=2, dim=-1)\n",
    "        \n",
    "        return image_embedding, text_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# In[5]: 设置设备和数据集\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 加载CIFAR10数据集\n",
    "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# In[6]: 初始化模型\n",
    "model = CLIP(embedding_dim=512).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[2]: 实现Triplet Loss\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.2):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def forward(self, img_emb, text_emb):\n",
    "        # 计算正例对的相似度\n",
    "        img_text_similarity = torch.matmul(img_emb, text_emb.t()).diag()\n",
    "        \n",
    "        # 创建负例对（通过循环移位）\n",
    "        n = img_emb.shape[0]\n",
    "        original_list = list(range(n))\n",
    "        shifted_list = original_list[1:] + [original_list[0]]\n",
    "        shuffled_image = img_emb[shifted_list]\n",
    "        shuffled_text = text_emb[shifted_list]\n",
    "        \n",
    "        # 计算与负例的相似度\n",
    "        neg_sim_img = torch.matmul(img_emb, shuffled_text.t()).diag()\n",
    "        neg_sim_text = torch.matmul(text_emb, shuffled_image.t()).diag()\n",
    "        \n",
    "        # 计算triplet loss\n",
    "        img_loss = torch.clamp(self.margin + neg_sim_img - img_text_similarity, min=0)\n",
    "        text_loss = torch.clamp(self.margin + neg_sim_text - img_text_similarity, min=0)\n",
    "        \n",
    "        return (img_loss.mean() + text_loss.mean()) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In[3]: 实现Embedding Queue\n",
    "class EmbeddingQueue:\n",
    "    def __init__(self, max_size=15):\n",
    "        self.max_size = max_size\n",
    "        self.image_queue = []\n",
    "        self.text_queue = []\n",
    "    \n",
    "    def add_queue(self, image_embedding, text_embedding):\n",
    "        \"\"\"添加新的embeddings到队列并维护最大大小\"\"\"\n",
    "        self.image_queue.append(image_embedding)\n",
    "        self.text_queue.append(text_embedding)\n",
    "        \n",
    "        # 如果队列超过最大大小，移除最旧的embeddings\n",
    "        if len(self.image_queue) > self.max_size:\n",
    "            self.image_queue.pop(0)\n",
    "            self.text_queue.pop(0)\n",
    "    \n",
    "    def return_values(self):\n",
    "        \"\"\"返回存储的embeddings\"\"\"\n",
    "        return self.image_queue, self.text_queue\n",
    "    \n",
    "    def clear(self):\n",
    "        \"\"\"清除所有存储的embeddings\"\"\"\n",
    "        self.image_queue = []\n",
    "        self.text_queue = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_queue(model, dataloader, optimizer, scaler, epoch, embedding_queue=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f'Epoch {epoch}')\n",
    "    for batch_idx, (images, labels) in enumerate(pbar):\n",
    "        images = images.to(device)\n",
    "        texts = [f\"This is an image of a {train_dataset.classes[label]}\" for label in labels]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            img_emb, text_emb = model(images, texts)\n",
    "            \n",
    "            if embedding_queue is not None:\n",
    "                # 更新队列中的embedding\n",
    "                with torch.no_grad():  # 添加这行，避免梯度计算\n",
    "                    embedding_queue.add_queue(img_emb.clone().detach(), \n",
    "                                           text_emb.clone().detach())\n",
    "                \n",
    "                saved_img_embeddings, saved_text_embeddings = embedding_queue.return_values()\n",
    "                \n",
    "                if len(saved_img_embeddings) > 0:\n",
    "                    # 合并当前batch和队列中的embeddings\n",
    "                    queue_img = torch.cat(saved_img_embeddings, dim=0)\n",
    "                    queue_text = torch.cat(saved_text_embeddings, dim=0)\n",
    "                    \n",
    "                    # 确保维度对齐\n",
    "                    img_mat = torch.cat([img_emb, queue_img.to(device)], dim=0)\n",
    "                    text_mat = torch.cat([text_emb, queue_text.to(device)], dim=0)\n",
    "                else:\n",
    "                    img_mat = img_emb\n",
    "                    text_mat = text_emb\n",
    "            \n",
    "            # 计算损失时只使用当前batch的标签\n",
    "            labels = torch.arange(img_emb.shape[0]).to(device)\n",
    "            logits_img_text = torch.matmul(img_emb, text_mat.t()) * 2\n",
    "            logits_text_img = torch.matmul(text_emb, img_mat.t()) * 2\n",
    "            \n",
    "            img_text_loss = F.cross_entropy(logits_img_text, labels)\n",
    "            text_img_loss = F.cross_entropy(logits_text_img, labels)\n",
    "            loss = (img_text_loss + text_img_loss) / 2\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[5]: 实现实验运行和结果记录函数\n",
    "def run_experiments(model, train_dataset, test_dataset, config):\n",
    "    results = {\n",
    "        'original': {'loss': [], 'accuracy': []},\n",
    "        'triplet': {'loss': [], 'accuracy': []},\n",
    "        'queue': {'loss': [], 'accuracy': []}\n",
    "    }\n",
    "    \n",
    "    for method in ['original', 'triplet', 'queue']:\n",
    "        print(f\"\\nTraining with {method} method...\")\n",
    "        \n",
    "        # 重置模型\n",
    "        model.load_state_dict(torch.load('initial_weights.pth'))\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "        scaler = GradScaler()\n",
    "        \n",
    "        if method == 'queue':\n",
    "            embedding_queue = EmbeddingQueue(max_size=config['queue_size'])\n",
    "        else:\n",
    "            embedding_queue = None\n",
    "        \n",
    "        for epoch in range(config['epochs']):\n",
    "            # 训练\n",
    "            if method == 'triplet':\n",
    "                loss = train_with_triplet_loss(model, train_loader, optimizer, scaler, epoch)\n",
    "            elif method == 'queue':\n",
    "                loss = train_with_queue(model, train_loader, optimizer, scaler, epoch, embedding_queue)\n",
    "            else:\n",
    "                loss = train_one_epoch(model, train_loader, optimizer, scaler, epoch)\n",
    "            \n",
    "            # 评估\n",
    "            accuracy = evaluate(model, test_dataset)\n",
    "            \n",
    "            # 记录结果\n",
    "            results[method]['loss'].append(loss)\n",
    "            results[method]['accuracy'].append(accuracy)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{config['epochs']}\")\n",
    "            print(f\"Loss: {loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[6]: 实现结果可视化函数\n",
    "def plot_experimental_results(results):\n",
    "    # 创建图表\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # 绘制损失曲线\n",
    "    for method in results.keys():\n",
    "        ax1.plot(results[method]['loss'], label=method)\n",
    "    ax1.set_title('Training Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # 绘制准确率曲线\n",
    "    for method in results.keys():\n",
    "        ax2.plot(results[method]['accuracy'], label=method)\n",
    "    ax2.set_title('Test Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# In[7]: 实现基础训练和评估函数\n",
    "def train_one_epoch(model, dataloader, optimizer, scaler, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f'Epoch {epoch}')\n",
    "    for batch_idx, (images, labels) in enumerate(pbar):\n",
    "        images = images.to(device)\n",
    "        texts = [f\"This is an image of a {train_dataset.classes[label]}\" for label in labels]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            img_emb, text_emb = model(images, texts)\n",
    "            \n",
    "            # 计算损失\n",
    "            labels = torch.arange(img_emb.shape[0]).to(device)\n",
    "            logits_img_text = torch.matmul(img_emb, text_emb.t()) * 2\n",
    "            logits_text_img = torch.matmul(text_emb, img_emb.t()) * 2\n",
    "            \n",
    "            img_text_loss = F.cross_entropy(logits_img_text, labels)\n",
    "            text_img_loss = F.cross_entropy(logits_text_img, labels)\n",
    "            loss = (img_text_loss + text_img_loss) / 2\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        # 清理内存\n",
    "        if batch_idx % 10 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def train_with_triplet_loss(model, dataloader, optimizer, scaler, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    triplet_criterion = TripletLoss()\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f'Epoch {epoch}')\n",
    "    for batch_idx, (images, labels) in enumerate(pbar):\n",
    "        images = images.to(device)\n",
    "        texts = [f\"This is an image of a {train_dataset.classes[label]}\" for label in labels]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            img_emb, text_emb = model(images, texts)\n",
    "            loss = triplet_criterion(img_emb, text_emb)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, test_dataset):\n",
    "    model.eval()\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc='Evaluating'):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 为每个类别生成文本描述\n",
    "            class_texts = [f\"This is an image of a {test_dataset.classes[i]}\" for i in range(len(test_dataset.classes))]\n",
    "            \n",
    "            # 获取图像嵌入\n",
    "            img_emb, _ = model(images, [\"dummy text\"])  # 文本参数在这里不重要\n",
    "            \n",
    "            # 获取所有类别的文本嵌入\n",
    "            _, text_emb = model(torch.zeros_like(images[:1]), class_texts)\n",
    "            \n",
    "            # 计算相似度\n",
    "            similarity = torch.matmul(img_emb, text_emb.t())\n",
    "            \n",
    "            # 获取预测\n",
    "            _, predicted = similarity.max(1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with original method...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ffa0e670b024d4f8041ca643ca31af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92930d99d7ee4e7c9f3aaa63f55b3d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Loss: 2.1633, Accuracy: 92.38%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1ca9bbd5884957a252dfb6e7022c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd0727316e147e386cf9bcdde2b20bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "Loss: 2.0398, Accuracy: 92.17%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a789f319110e4288862e0478f16a5206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabb71800bd6453292e8d3e94dc371be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "Loss: 2.0156, Accuracy: 93.86%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbee9a1a1764844a60bce44660bc39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf3c182fd624cb3b2958ec5d08fb6e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "Loss: 1.9966, Accuracy: 94.02%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c629e786bb41446da6728c6e0ef8cc35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6670fcd696c74acb951bf54f2bc91272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "Loss: 1.9854, Accuracy: 93.55%\n",
      "\n",
      "Training with triplet method...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8d2abe00af49f78f89cf40b88843df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b8b84c3f894deaab74079d29dd35b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Loss: 0.0371, Accuracy: 85.79%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d80538d77a4e71abb83ec2ae09b6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0adcccdf474595827b337709e5392a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "Loss: 0.0290, Accuracy: 85.94%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9cdb212c8eb41cb9e938c6bea5dfd42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909493f02d294cef8d54972ba8b3e495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "Loss: 0.0280, Accuracy: 89.63%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043a50ef4f6c49f38ca053ee3185e795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69cf83ec54304704ad7cf18108babe2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "Loss: 0.0269, Accuracy: 88.55%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8096de6445842319bdd13fd36b101fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f5e77643fb84eb79165edde49427c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "Loss: 0.0272, Accuracy: 89.97%\n",
      "\n",
      "Training with queue method...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b41b2419244970b4458f2a3ca056ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16cba6a90098425986ccf6f6912e2148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Loss: 6.1628, Accuracy: 10.08%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3b70d44d284272b2d40afd3a4f27af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fdcc262ddf140329f921b6d1dec3a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "Loss: 6.2687, Accuracy: 10.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0563879e5a8461fbc6fe55a65c1f3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d54e9e125f4047a4e9fdf520e1f37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "Loss: 6.2226, Accuracy: 10.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82bdf6b9ae13437b8b29c244168551b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In[7]: 运行实验\n",
    "config = {\n",
    "    'learning_rate': 1e-4,\n",
    "    'epochs': 5,\n",
    "    'batch_size': 32,\n",
    "    'queue_size': 30\n",
    "}\n",
    "\n",
    "# 保存初始权重\n",
    "torch.save(model.state_dict(), 'initial_weights.pth')\n",
    "\n",
    "# 运行实验\n",
    "results = run_experiments(model, train_dataset, test_dataset, config)\n",
    "\n",
    "# 可视化结果\n",
    "plot_experimental_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "Original method: 93.20% accuracy\n",
      "Triplet method: 90.05% accuracy\n",
      "Queue method: 10.18% accuracy\n"
     ]
    }
   ],
   "source": [
    "# In[8]: 打印最终结果\n",
    "print(\"\\nFinal Results:\")\n",
    "for method in results.keys():\n",
    "    final_accuracy = results[method]['accuracy'][-1]\n",
    "    print(f\"{method.capitalize()} method: {final_accuracy:.2f}% accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (clip)",
   "language": "python",
   "name": "clip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
